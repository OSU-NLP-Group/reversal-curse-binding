{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_factor = 40\n",
    "\n",
    "with open(f\"llm_tests/all_facts_{branching_factor}.json\", \"r\", encoding='utf-8') as f:\n",
    "    all_facts = json.load(f)\n",
    "with open(f\"llm_tests/X_values_{branching_factor}.json\", \"r\", encoding='utf-8') as f:\n",
    "    X_values = json.load(f)\n",
    "\n",
    "print(f\"{np.mean([len(all_facts[str(i)]) for i in range(20)])} facts on average.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 10007\n",
    "core_v_multiplicity = 10\n",
    "num_core_entities = P * core_v_multiplicity\n",
    "core_entities = set([\"<c_{}>\".format(i) for i in range(num_core_entities)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some random names\n",
    "import names\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "all_names = set()\n",
    "for _ in tqdm(range(100000)):\n",
    "    n = fake.name().split()\n",
    "    if len(n) != 2:\n",
    "        continue\n",
    "    all_names.add(n[0].strip())\n",
    "for _ in tqdm(range(50000)):\n",
    "    all_names.add(names.get_first_name().strip())\n",
    "\n",
    "all_names = list(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core2val(c):\n",
    "    return int(c.strip(\"><c_\")) % P\n",
    "\n",
    "def form_rel_fact(arr, ent2name):\n",
    "    if np.random.uniform() < 0.5:\n",
    "        [e1, e2, e3] = arr\n",
    "    else:\n",
    "        [e2, e1, e3] = arr\n",
    "    return f\"{ent2name[e1]}'s number plus {ent2name[e2]}'s number is {ent2name[e3]}'s number.\"\n",
    "\n",
    "def form_attr_fact(c, ent2name):\n",
    "    return f\"The number of {ent2name[c]} is {core2val(c)}.\"\n",
    "\n",
    "prompt_template = \\\n",
    "\"\"\"\n",
    "In the following facts, names correspond to different people as long as their *spellings* are different. For example, 'Jackelyn' and 'Jackeline' represent two *different* people.\n",
    "\n",
    "Here are the facts:\n",
    "\n",
    "{}\n",
    "\n",
    "Different people could have the same number.\n",
    "\n",
    "What is {}'s number? Your response should end by 'Final Answer: XXX.' \n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_id in range(len(all_facts)):\n",
    "    \n",
    "    facts, gt_answer = all_facts[str(example_id)], X_values[example_id]\n",
    "\n",
    "    core_ents, other_ents = set(), set()\n",
    "\n",
    "    for (e1, e2, e3) in facts:\n",
    "        assert e2 in core_entities\n",
    "        core_ents.add(e2)\n",
    "        if e1 in core_entities:\n",
    "            assert e3 not in core_entities\n",
    "            core_ents.add(e1)\n",
    "            other_ents.add(e3)\n",
    "        elif e3 in core_entities:\n",
    "            assert e1 not in core_entities\n",
    "            core_ents.add(e3)\n",
    "            other_ents.add(e1)\n",
    "        else:\n",
    "            other_ents.add(e1)\n",
    "            other_ents.add(e3)\n",
    "\n",
    "    target_ent = f'<x_{example_id}>'\n",
    "    assert target_ent in other_ents\n",
    "\n",
    "    all_ents = list(core_ents | other_ents)\n",
    "    assert len(all_ents) == len(core_ents) + len(other_ents)\n",
    "    assert len(all_names) >= len(all_ents)\n",
    "\n",
    "    temp_names = deepcopy(all_names[:len(all_ents)])\n",
    "    random.shuffle(all_ents)\n",
    "    ent2name = {a:b for a,b in zip(all_ents, temp_names)}\n",
    "\n",
    "    facts_verbalized = []\n",
    "\n",
    "    # relational facts\n",
    "    for fa in facts:\n",
    "        facts_verbalized.append(form_rel_fact(fa, ent2name))\n",
    "    # atomic facts of core entities\n",
    "    for c in core_ents:\n",
    "        facts_verbalized.append(form_attr_fact(c, ent2name))\n",
    "\n",
    "    random.shuffle(facts_verbalized)\n",
    "    facts_verbalized = \" \".join(facts_verbalized)\n",
    "\n",
    "    # final string\n",
    "    prompt = prompt_template.format(facts_verbalized, ent2name[target_ent])\n",
    "\n",
    "    with open(f\"llm_tests/q_{branching_factor}_{example_id}.txt\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(prompt)\n",
    "\n",
    "    with open(f\"llm_tests/a_{branching_factor}_{example_id}.txt\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(gt_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branching_factor: 10| 17 correct, 0 can't determine, 3 wrong (out of 20)\n",
      "branching_factor: 20| 4 correct, 1 can't determine, 15 wrong (out of 20)\n",
      "branching_factor: 30| 0 correct, 2 can't determine, 18 wrong (out of 20)\n",
      "branching_factor: 40| 0 correct, 4 can't determine, 16 wrong (out of 20)\n"
     ]
    }
   ],
   "source": [
    "# evaluating o3mini\n",
    "\n",
    "for branching_factor in [10, 20, 30, 40]:\n",
    "\n",
    "    with open(f\"llm_tests/o3mini_results/gsm_o3mini_{branching_factor}.json\", \"r\", encoding='utf-8') as f:\n",
    "        all_items = json.load(f)\n",
    "\n",
    "    correct = 0\n",
    "    cannot_determine = 0\n",
    "    for i, item in enumerate(all_items):\n",
    "        gt_ans = int(item['answer'].strip(\"><\"))\n",
    "        try:\n",
    "            temp = item['response'].split(\"Final Answer:\")[-1].strip(\". *\")\n",
    "            if gt_ans == int(temp):\n",
    "                correct += 1\n",
    "                # print(f\"--->\\t '{i} correct'\")\n",
    "            else:\n",
    "                pass\n",
    "                # print(f\"--->\\t '{i} wrong'\")\n",
    "        except:\n",
    "            # print(f\"--->\\t '{i} undet'\")\n",
    "            cannot_determine += 1\n",
    "    print(f\"branching_factor: {branching_factor}| {correct} correct, {cannot_determine} can't determine, {len(all_items) - correct - cannot_determine} wrong (out of {len(all_items)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branching_factor: 10| 9 correct, 0 can't determine, 11 wrong (out of 20)\n",
      "branching_factor: 20| 9 correct, 0 can't determine, 11 wrong (out of 20)\n",
      "branching_factor: 30| 7 correct, 0 can't determine, 13 wrong (out of 20)\n",
      "branching_factor: 40| 5 correct, 2 can't determine, 13 wrong (out of 20)\n"
     ]
    }
   ],
   "source": [
    "# eval gemini\n",
    "\n",
    "import re\n",
    "def extract_first_number_regex(text):\n",
    "    # Find the first occurrence of a number\n",
    "    match = re.search(r'\\d+', text)\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "for branching_factor in [10, 20, 30, 40]:\n",
    "\n",
    "    correct = 0\n",
    "    cannot_determine = 0\n",
    "    for example_id in range(20):\n",
    "        with open(f\"llm_tests/gemini_results/{branching_factor}_{example_id}\") as f:\n",
    "            data = json.load(f)\n",
    "        with open(f\"llm_tests/a_{branching_factor}_{example_id}.txt\") as f:\n",
    "            gold_ans = int(f.read().strip(\" <>\"))\n",
    "\n",
    "        try:\n",
    "            pred_ans = data['chunkedPrompt']['chunks'][-1]['text'].split(\"Final Answer:\")[1].strip(\". \\n\")\n",
    "            pred_ans = int(extract_first_number_regex(pred_ans))\n",
    "            if pred_ans == gold_ans:\n",
    "                correct += 1\n",
    "                # print(example_id, \"correct\")\n",
    "                pass\n",
    "            else:\n",
    "                # print(example_id, \"wrong\")\n",
    "                pass\n",
    "        except:\n",
    "            # print(example_id, \"no ans\")\n",
    "            cannot_determine += 1\n",
    "\n",
    "    print(f\"branching_factor: {branching_factor}| {correct} correct, {cannot_determine} can't determine, {20 - correct - cannot_determine} wrong (out of {20})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
